# Дипломная работа по профессии Инженер данных
##### Алексей Омельченко

## Задание

1. Вам необходимо разработать и задокументировать ETL-процессы заливки данных в хранилище, состоящее из слоёв:
    - NDS - нормализованное хранилище и DDS - схема звезда;
    - Data Quality - опционально, будет большим преимуществом в вашей работе;
2. На основании DDS построить в Табло дашборды

### Цель: составить документацию процессов ETL на основе предложенного датасета
1. Этапы выполнения дипломной работы
2. Обработайте и проанализируйте данные
3. Сформируйте нормализованную схему данных (NDS)
4. Сформируйте состав таблиц фактов и измерений (DDS)
5. Сформируйте ETL-процессы: для заливки данных в NDS и для создания витрин
6. Сформируйте набор метрик и дашбордов на их основе
7. Оформите результаты, сформулируйте выводы

### Рекомендации при выполнении работы:
1. ETL процессы можно делать:
    - с помощью Pentaho;
    - с помощью Python (pandas) + SQL;
2. датасет:
    - предложен вам в CSV формате выше;
    - сбор данных вы также можете сделать из сторонних API, это станет вашим преимуществом;
3. Дополнительно вы можете сделать оркестровку с помощью Airflow;
4. Опционально можно сделать отдельный слой метаданных в хранилище, а также дашборды на основании данных из этого слоя, где будет отображаться кол-во прогрузок и их статусы;


### Результат:
- дашборды
- задокументированная схема хранилища данных
- документированная схема ETL-процессов

Формат выполнения: дипломная работа носит комплексный подход, поэтому рекомендуем подготовить к защите воркбуки Табло, ERR-диаграммы для схемы хранилища + ktr/kjb файлы с ETL-процессами или py-файлы с DAG Airflow


## Краткое описание решения
## Анализ данных

## Нормальная форма данных
Для хранения данных в третьей нормальной форме используются следующие таблицы:
#### sales_nf - таблица инвойсов
	invoice_id STRING, -- идентификатор инвойса  
	branch INT64, -- идентификатор подразделения  
	city INT64, -- идентификатор города  
	product_line INT64, -- идентификатор группы товаров  
	payment_type INT64, -- идентификатор платежного средства  
	member_status INT64, -- идентификатор типа участия в программе лояльности  
	gender INT64, -- идентификатор гендера  
	transaction_time DATETIME, -- время транзакции  
	amount INT64, -- количество купленного товарар в штуках  
	unit_price NUMERIC(8, 2), -- цена за 1 единицу товара  
	cost NUMERIC(8, 2), -- себестоимость покупки  
	rating NUMERIC(2, 2) -- рейтинг покупки, оставленный покупателем  
#### cities - справочник городов  
	city_id INT64 - идентификатор города  
	city_name STRING - название города  
#### branches - справочник подразделений  
	branch_id INT64 - идентификатор подразделения  
	branch_name STRING -- название подразделения   
#### payment_types - справочник типов платежных средств
	payment_type_id INT64 - идентификатор платежного средства  
	payment_type_name STRING - название платежного средства  
#### genders - справочник гендеров  
	gender_id INT64 - идентификатор гендера  
	gender_name STRING - название гендера  
#### member_statuses - справочник статусов участника программы лояльности
	member_status_id INT64 - идентификатор участника  
	member_status_name STRING - название статуса участника программы лояльности  
#### product_lines - справочник групп товаров  
	member_status_id INT64 - идентификатор группы товаров  
	member_status_name STRING - название группы товаров  

Справочники связаны с таблицей инвойсов отношением **один ко многим** через идентификаторы.  
Часть столбцов из источника данных, такие как **Tax 5%**, **Total**, **gross margin percentage**,	**gross income** не включены в нормальную форму, т.к. они вычисляются на основе полей **amount**, **unit_price** и **cost**
  

## Таблицы фактов и измерений
## Генерация тестовых данных
Состав получаемых данных описан в разделе [Анализ данных](https://github.com/AlexeyOm/netology-diplom-deg-13#%D0%B0%D0%BD%D0%B0%D0%BB%D0%B8%D0%B7-%D0%B4%D0%B0%D0%BD%D0%BD%D1%8B%D1%85). Для их имитации и генерации большего объёма данных я буду использовать сервис mockaroo.com, предоставляющий возможность генерировать данные с использованием типовых полей, таких как пол, дата, время, а также формул, генераторов случайных чисел и условных операторов. Описание схемы данных доступно по [ссылке](https://www.mockaroo.com/07cd64d0). На базе сервиса mockaroo создано API, доступное по URL https://my.api.mockaroo.com/mock_sales_data.csv?key=78343830&date=2023-03-05.

Поле date генерируется на основе параметра date в запросе, проверка не производится, будет использован любой переданный текст. В случае отсутствия текста в поле date будет пустое значение.
**Данные в поле Data могут быть пустые или сообщением об ошибке, если автор схемы не выполнил логин в сервис mockaroo или разлогинился по времени**
В случае, если сервер перегружен и данные не успевают сгенерироваться за 30 секунд, вместо данных API выдает сообщение об ошибке {"error":"Your handler script took too long to execute. The handler script must execute in under 30 seconds"}. Необходимо проверять это событие при загрузке данных и планировать повторное обращение к серверу через определенный промежуток времени.

С вероятностью 1% для каждого поля, данные в столбцах Customer type, Gender, Product line, Date, Time будут пусты для имитации некачественных данных и ошибок.

Данные по API загружаются в формате csv, разделитель - запятая, заголовки столбцов в первой строке.
## ETL процессы
Процесс обработки данных происходит по следующему сценарию
1. Загрузка исходного файла
2. Проверка файла с помощью пакета Great Expectations
3. Разделение данных файла на два датасета - датасет данных, прошедших валидацию, и датасет данных, не прошедших
4. Запись данных, не прошедших валидацию в таблицу BigQuery для ручного анализа ошибок
5. Отправка предупреждения на почту ответственного за качество данных в случае выявления некорректных данных
6. Запись данных, прошедших валидацию, в нормальной форме в таблицы BigQuery
7. Запись данных, прошедших валидацию, в таблицы фактов и измерений
8. Отправка сообщения на почту ответственного за качество данных в случае успешной загрузки или предупреждения в случае ошибки
## Оркестрация
## Качество данных
## Вывод
## Ссылки